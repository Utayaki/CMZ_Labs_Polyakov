{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83bca3-37fc-45fc-af4e-178ecdb4aac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9526707e-c13e-41b9-8d6a-c0e289bbe035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "class BloatWareConvTranspose2D():\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, dtype=None):\n",
    "        \n",
    "        if isinstance(in_channels, int) and in_channels > 0:\n",
    "            self.in_channels = in_channels\n",
    "        else:\n",
    "            raise ValueError(\"Invalid in_channels\")\n",
    "        \n",
    "        if isinstance(out_channels, int) and out_channels > 0:\n",
    "            self.out_channels = out_channels\n",
    "        else:\n",
    "            raise ValueError(\"Invalid out_channels\")\n",
    "        \n",
    "        if isinstance(groups, int) and groups > 0:\n",
    "            self.groups = groups\n",
    "        else:\n",
    "            raise ValueError(\"Invalid groups\")\n",
    "\n",
    "        if isinstance(stride, int) and stride > 0:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            raise ValueError(\"Invalid stride\")\n",
    "        \n",
    "        if isinstance(padding, int) and padding > -1:\n",
    "            self.padding = padding\n",
    "        else:\n",
    "            raise ValueError(\"Invalid padding\")\n",
    "            \n",
    "        if isinstance(output_padding, int) and output_padding > -1:\n",
    "            self.output_padding = output_padding\n",
    "        else:\n",
    "            raise ValueError(\"Invalid output_padding\")\n",
    "            \n",
    "        if isinstance(dilation, int) and dilation > 0:\n",
    "            self.dilation = dilation\n",
    "        else:\n",
    "            raise ValueError(\"Invalid dilation\")\n",
    "            \n",
    "        if not((self.in_channels % self.groups == 0) and (self.out_channels % self.groups == 0)):\n",
    "            raise ValueError(\"in_channels and out_channels must both be divisible by groups\")\n",
    "        \n",
    "        if (self.output_padding >= self.dilation and self.output_padding >= self.stride) or (self.output_padding >= self.dilation and self.output_padding >= self.stride):\n",
    "            raise ValueError(\"output_padding should be smaller than dilation or stride\")\n",
    "\n",
    "        if bias == True:\n",
    "          self.bias = torch.rand(self.out_channels)\n",
    "        else:\n",
    "          self.bias = torch.zeros(self.out_channels)\n",
    "    \n",
    "        if isinstance(kernel_size, int):\n",
    "            self.weight = torch.rand(\n",
    "                self.in_channels,\n",
    "                self.out_channels,\n",
    "                kernel_size,\n",
    "                kernel_size,\n",
    "            )\n",
    "            self.kernel_size = kernel_size\n",
    "        else:\n",
    "            raise ValueError(\"kernel size must be int or tuple\")\n",
    "\n",
    "        self.dtype = dtype\n",
    "    \n",
    "    def forward(self, input_tensor):\n",
    "        result = []\n",
    "\n",
    "        for l in range(self.out_channels):\n",
    "    \n",
    "          feature_map = torch.zeros((input_tensor.shape[1]-1)*self.stride + self.dilation * (self.kernel_size-1)+1, (input_tensor.shape[2]-1)*self.stride  + self.dilation * (self.kernel_size-1)+1 ) #генерация пустой feature-map\n",
    "          for c in range (self.in_channels):\n",
    "    \n",
    "            for i in range (0, input_tensor.shape[1]):  #проход по всем пикселям изображения\n",
    "              for j in range (0, input_tensor.shape[2]):\n",
    "    \n",
    "                val = input_tensor[c][i][j]\n",
    "                proizv = val*self.weight[c][l]\n",
    "    \n",
    "                zero_tensor = torch.zeros((self.weight.shape[2]-1)*self.dilation+1, (self.weight.shape[3]-1)*self.dilation+1)\n",
    "    \n",
    "                for a in range (0, zero_tensor.shape[0], self.dilation):\n",
    "                  for b in range (0, zero_tensor.shape[1], self.dilation):\n",
    "                    zero_tensor[a][b] = proizv[a//self.dilation][b//self.dilation]\n",
    "    \n",
    "                res = np.add((zero_tensor), feature_map[i*self.stride:i*self.stride+(self.weight.shape[2]-1)*self.dilation+1, j*self.stride:j*self.stride+(self.weight.shape[3]-1)*self.dilation+1])\n",
    "                feature_map[i*self.stride:i*self.stride+(self.weight.shape[2]-1)*self.dilation+1, j*self.stride:j*self.stride+(self.weight.shape[3]-1)*self.dilation+1] = res\n",
    "    \n",
    "    \n",
    "          result.append(np.add(feature_map, np.full((feature_map.shape), self.bias[l])))\n",
    "    \n",
    "    \n",
    "        for t in range(len(result)):\n",
    "          if self.output_padding > 0:\n",
    "            pad_func = torch.nn.ConstantPad1d((0, self.output_padding, 0, self.output_padding), 0)\n",
    "            result[t] = pad_func(result[t])\n",
    "    \n",
    "          result[t] = result[t][0+self.padding:result[t].shape[0]-self.padding, 0+self.padding:result[t].shape[1]-self.padding]\n",
    "\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4fde7dab-2430-42cc-b350-7635b35ddbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchConvTranspose2D = torch.nn.ConvTranspose2d(15, 5, 3, stride=1, padding=1, dilation=1)\n",
    "input_image = torch.randn(15, 50, 50)\n",
    "output = torchConvTranspose2D(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "16474b3d-b96f-4e76-9336-7cac7c3f5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "myConvTranspose2D = BloatWareConvTranspose2D(15, 5, 3, stride=1, padding=1, dilation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e17ce15d-53cf-46d0-9746-97fbc7d9e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myConvTranspose2D.weight = torchConvTranspose2D.weight.detach().numpy()\n",
    "myConvTranspose2D.bias = torchConvTranspose2D.bias.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a29ff7d8-4cf8-42be-93b0-455344316d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mock = myConvTranspose2D.forward(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "08cb2ac4-1c35-434e-803c-1fe27beec5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.4144e-02, -4.0830e-01,  1.3812e-01,  ...,  3.5826e-01,\n",
       "          -3.6301e-01, -6.4993e-02],\n",
       "         [-5.9811e-01,  1.0341e+00,  7.8236e-01,  ..., -2.6313e-01,\n",
       "          -1.2244e-01,  6.8067e-01],\n",
       "         [ 1.2285e+00, -1.9864e+00, -7.7189e-01,  ..., -9.3731e-01,\n",
       "          -4.7767e-01,  4.5403e-01],\n",
       "         ...,\n",
       "         [-1.4497e-01, -6.2573e-01, -3.1614e-01,  ..., -5.7800e-01,\n",
       "          -1.1800e+00,  4.7009e-01],\n",
       "         [-1.8099e+00, -1.4266e+00, -1.3338e+00,  ..., -2.2716e-01,\n",
       "           3.2290e-01,  6.4719e-02],\n",
       "         [-5.1554e-01,  5.6257e-01, -1.2997e+00,  ...,  8.3713e-01,\n",
       "          -2.6759e-01, -6.0303e-01]],\n",
       "\n",
       "        [[ 1.9259e-01,  6.9018e-02, -3.2970e-01,  ...,  2.5642e-01,\n",
       "           7.8945e-01,  1.4418e-01],\n",
       "         [ 3.6651e-01, -1.2020e-01,  1.2002e+00,  ..., -1.4035e+00,\n",
       "          -7.4276e-02,  6.1441e-01],\n",
       "         [-8.2292e-01, -2.6048e-01,  7.5872e-01,  ...,  8.0376e-01,\n",
       "          -5.7097e-02, -2.7008e-01],\n",
       "         ...,\n",
       "         [ 3.0044e-01,  5.0188e-01,  1.1443e+00,  ..., -1.1189e+00,\n",
       "          -1.0332e-01, -3.2936e-01],\n",
       "         [-3.8912e-01,  9.2292e-01,  6.0829e-01,  ..., -7.3345e-01,\n",
       "          -8.3653e-01,  3.0597e-01],\n",
       "         [-2.5551e-01, -6.3865e-01, -4.3700e-01,  ...,  1.2326e-01,\n",
       "          -5.3485e-01, -5.0198e-01]],\n",
       "\n",
       "        [[ 1.6024e+00, -3.9867e-01, -2.3229e+00,  ...,  8.8125e-01,\n",
       "           2.8629e-01,  1.1285e+00],\n",
       "         [-2.5942e-01,  5.5198e-01,  3.7531e-02,  ...,  7.5903e-02,\n",
       "          -4.2892e-01, -1.2838e-01],\n",
       "         [ 9.0904e-01,  4.4960e-02,  4.6389e-01,  ..., -2.5687e+00,\n",
       "           9.4889e-01,  8.1098e-01],\n",
       "         ...,\n",
       "         [ 9.7812e-01,  1.2538e+00,  1.4465e+00,  ...,  2.4824e+00,\n",
       "          -8.5762e-01,  1.1674e+00],\n",
       "         [ 2.1358e-01,  5.3688e-01,  8.4684e-01,  ..., -3.9039e-01,\n",
       "           9.2371e-01, -6.3270e-01],\n",
       "         [ 5.8563e-01,  1.5522e-01,  2.2289e-02,  ..., -2.5548e-02,\n",
       "          -1.6469e-01, -2.1958e-01]],\n",
       "\n",
       "        [[ 5.3772e-01,  9.0224e-02, -1.0034e-01,  ..., -9.8978e-01,\n",
       "          -2.0420e+00, -4.0756e-01],\n",
       "         [-1.1661e+00, -2.1714e-02,  7.3644e-01,  ..., -9.5229e-01,\n",
       "           5.7518e-01,  1.9946e-02],\n",
       "         [ 4.3003e-01, -4.0792e-01, -4.0521e-01,  ...,  2.6728e-01,\n",
       "           9.8996e-05, -1.0249e-01],\n",
       "         ...,\n",
       "         [-5.1518e-01, -2.8687e-01, -6.7892e-01,  ...,  1.0663e+00,\n",
       "           2.2430e-01, -2.5989e-01],\n",
       "         [-7.1713e-01, -1.6441e+00, -7.9927e-01,  ..., -2.9860e+00,\n",
       "          -8.6038e-01, -6.4875e-01],\n",
       "         [-3.0830e-01, -4.9046e-01,  3.7271e-01,  ...,  8.5278e-01,\n",
       "           7.0557e-01,  2.0247e-01]],\n",
       "\n",
       "        [[ 5.9403e-01, -6.9148e-01, -4.6763e-02,  ..., -1.7108e-01,\n",
       "          -1.1904e+00, -1.6885e-01],\n",
       "         [ 2.4879e-01, -1.9311e+00,  9.9646e-01,  ..., -1.0640e+00,\n",
       "          -5.3004e-01,  1.1798e+00],\n",
       "         [-9.8156e-03, -2.8814e-01, -1.4892e+00,  ..., -1.2450e+00,\n",
       "           3.5182e-01,  2.4523e+00],\n",
       "         ...,\n",
       "         [ 9.4067e-01,  9.3843e-01, -6.8922e-01,  ...,  2.1697e+00,\n",
       "           2.3164e+00, -1.3985e-01],\n",
       "         [ 9.3431e-01, -3.9618e-01,  6.9251e-01,  ..., -1.9261e+00,\n",
       "          -3.9679e-01,  8.8226e-01],\n",
       "         [ 6.6515e-01, -6.4125e-01, -1.1369e+00,  ...,  1.7280e+00,\n",
       "           2.6186e+00, -3.9577e-01]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3f0996b2-c3e2-4d7b-a56a-91dbced6d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = output.detach().numpy().astype(\"float16\") == output_mock.astype(\n",
    "    \"float16\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "250ef4e3-da99-4a24-a342-84384435b2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True, False,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b4c25-8cfd-46ed-baae-bdb8bdc656f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neyronki",
   "language": "python",
   "name": "neyronki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
